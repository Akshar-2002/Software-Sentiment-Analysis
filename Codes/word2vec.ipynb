{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc69ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109536ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS =nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d523e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9248bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18198f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "wv.fill_norms() \n",
    "wv.init_sims(replace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b22e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f365cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    cou=0\n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.key_to_index:\n",
    "            mean.append(wv.vectors[wv.key_to_index[word]])\n",
    "            all_words.add(wv.key_to_index[word])\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f170e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf179e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3898f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  oracle\n",
      "0  package file invalid phone factory reset wante...      -1\n",
      "1  iffy nice clean app sometimes works times does...      -1\n",
      "2                             cool freezes everytime      -1\n",
      "3  network error suddenly downloading update pack...      -1\n",
      "4  annoying let choose pictures want freezes forc...      -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input ['897392thanks', 'sharan']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  oracle\n",
      "0                                        guys stupid      -1\n",
      "1  lost whole morning cause hbases regionserver d...      -1\n",
      "2                       quote messing deep hbase dfs      -1\n",
      "3                   think going sweep shit kill root      -1\n",
      "4  idiot yeah idiotpath good commonslang hairball...      -1\n",
      "    id                                           sentence  oracle\n",
      "0    6                                      sadly working      -1\n",
      "1   78  everything builds fine try deploy application ...      -1\n",
      "2   90                     causing null pointer exception      -1\n",
      "3  139            attempts ive made shortcut unsuccessful      -1\n",
      "4  162                                           dont use      -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input ['file_name']\n",
      "WARNING:root:cannot compute similarity with no input ['file_name']\n",
      "WARNING:root:cannot compute similarity with no input ['api_name']\n",
      "WARNING:root:cannot compute similarity with no input ['logcat']\n",
      "WARNING:root:cannot compute similarity with no input ['code_fragment']\n",
      "WARNING:root:cannot compute similarity with no input ['file_name']\n",
      "WARNING:root:cannot compute similarity with no input ['code_fragment', 'code_fragment']\n",
      "WARNING:root:cannot compute similarity with no input ['insertandretriveblobdata']\n",
      "WARNING:root:cannot compute similarity with no input ['logcat']\n",
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input ['dispatherconfig']\n",
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input []\n",
      "WARNING:root:cannot compute similarity with no input ['shouldnt', 'fromindex', 'toindex']\n",
      "WARNING:root:cannot compute similarity with no input ['file_name', 'massagesalon']\n",
      "WARNING:root:cannot compute similarity with no input ['code_fragment']\n",
      "WARNING:root:cannot compute similarity with no input ['code_fragment', 'code_fragment']\n",
      "WARNING:root:cannot compute similarity with no input []\n"
     ]
    }
   ],
   "source": [
    "fn=['AppReviews','JIRA','StackOverflow']\n",
    "for k in range(0,3):\n",
    "    fname=fn[k]+'.csv'\n",
    "    df = pd.read_csv(fname,encoding='utf-8')\n",
    "    df['sentence'] = df['sentence'].apply(clean_text)\n",
    "    print(df.head())\n",
    "    comtdata=df\n",
    "    test_tokenized = comtdata.apply(lambda r: w2v_tokenize_text(r['sentence']), axis=1).values\n",
    "    X_comtdata_average1 = word_averaging_list(wv,test_tokenized)\n",
    "    fname=fn[k]+'w2v.csv'\n",
    "    np.savetxt(fname,X_comtdata_average1, delimiter=',', fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
