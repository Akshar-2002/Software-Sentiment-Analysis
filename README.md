# Software-Sentiment-Analysis

<h2>Introduction</h2>
The objective of the project is to classify the sentiments of software discussions on open source developer platforms - AppReviews, JIRA and Stack Overflow.
<br>Multiple models were built using various Word Embedding techniques and Classification Models and they were evaluated using Acuuracy and F1 Score metrics.<br/>
<br>The three Datasets used for the project - one each from JIRA, Stack Overflow and AppReviews can be found in the Datasets folder.<br/>

<h2>Word Embeddings</h2>
Six Word Embedding techniques were applied:
<br><br/>
<br>1. CountVec<br/>
<br>2. TF-IDF<br/>
<br>3. CBOW<br/>
<br>4. Skip-Gram<br/>
<br>5. Word2Vec<br/>
<br>6. GloVe 300d<br/>
<br>The codes for each of these word embeddings can be found in the Codes folder.<br/>
<br>The vector representation outputs obtained by applying these Word Embedding techniques on the three datasets can be found in the Embeddings folder<br/>

<h2>Classification Techniques</h2>
The predictive ability of the different Word Embedding techniques used are evaluated using 13 different classifiers
<br><br/>
<br>1. Multinomial Naive Bayes<br/>
<br>2. Bernoulliâ€™s Naive Bayes<br/>
<br>3. Gaussian Naive Bayes<br/>
<br>4. Complement Naive Bayes<br/>
<br>5. Decision Tree Classifier<br/>
<br>6. KNeighbours Classifier with Bagging Classifier<br/>
<br>7. RandomForestClassifier<br/>
<br>8. ExtraTreesClassifier<br/>
<br>9. AdaBoostClassifier<br/>
<br>10. GradientBoostingClassifier<br/>
<br>11. SVM with Linear Kernel<br/>
<br>12. SVM with Polynomial Kernel<br/>
<br>13. SVM with RBF Kernel<br/>
<br>The codes for each of these classifiers can be found in the 'Models.ipynb' file in the Codes folder.<br/>

<h2>Outputs</h2>
A total of 18 files (numbered from 1 to 18) are generated as output after applying the classification techniques on the word embedding generated files. These can be found in the Outputs folder.
<br>Each file consists of 14 columns, the first 13 corresponding to the outputs (predictions) of applying the 13 classifiers on the input word embedding generated file and the last column corresponds to the observed output for each data point.<br/>

The numbering system for the files is as follows:
<br><br/>
<br>1. Files 1.csv - 6.csv take input as files generated by applying word-embeddings on the AppReviews Dataset.<br/>
<br>2. Files 7.csv - 12.csv take input as files generated by applying word-embeddings on the JIRA Dataset.<br/>
<br>3. Files 13.csv - 18.csv take input as files generated by applying word-embeddings on the Stack Overflow Dataset.<br/>
<br>Each set of six files are generated by applying the following word embeddings in given order on the datasets: CountVec, TF-IDF, CBOW, Skip-Gram, Word2Vec, GloVe 300d<br/>

<h2>Evaluation Metrics</h2>
The generated models (18 word-embedding files * 13 Classifiers) are evaluated using Accuracy, Precision, Recall and F1 Metrics, the codes of which are in the 'Metrics.ipynb' file of the Codes folder.
<br><br/>
The output files are generated are as follows:
<br><br/>
<br>1. 'acc.csv' - Accuracies of all the models<br/>
<br>2. 'pre.csv' - Precision of all the models<br/>
<br>3. 'rec.csv' - Recall of all the models<br/>
<br>4. 'fmea'csv' - F1 Scores of all the models<br/>
<br>Each file consists of 18 rows, correspnding to the 18 Dataset - Word Embedding combinations and 13 columns, each corresponding to the 13 classification techniques.<br/> 
<br>The outout files can be found in the Output folder.<br/>
